import os
from pymongo import MongoClient
from sentence_transformers import SentenceTransformer
import chromadb
from chromadb.utils import embedding_functions
from bson.objectid import ObjectId
from dotenv import load_dotenv

load_dotenv()

# ==========================
# 1. C·∫§U H√åNH
# ==========================
MONGO_URI = os.getenv("MONGO_URI")
DATABASE_NAME = os.getenv("DATABASE_NAME", "knowledge_base")
CHROMA_PATH = os.getenv("CHROMA_PATH", "./chroma_db")

# Model embedding
sbert_model = SentenceTransformer("sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2")

# Embedding function cho ChromaDB
sbert_ef = embedding_functions.SentenceTransformerEmbeddingFunction(
    model_name="sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2"
)

def get_embeddings(texts):
    return sbert_model.encode(texts).tolist()

# ==========================
# 2. K·∫æT N·ªêI MONGODB
# ==========================
try:
    mongo_client = MongoClient(MONGO_URI)
    db = mongo_client[DATABASE_NAME]
    products_collection = db["products"]
    newstrend_collection = db["newstrend"]
    authors_collection = db["authors"]
    publishers_collection = db["publishers"]
    languages_collection = db["languages"]
    formats_collection = db["formats"]
    categories_collection = db["categories"]
    print("‚úÖ Connected to MongoDB successfully!")
except Exception as e:
    print(f"‚ùå Error connecting to MongoDB: {e}")
    exit()

# ==========================
# 3. KH·ªûI T·∫†O CHROMADB
# ==========================
try:
    chroma_client = chromadb.PersistentClient(path=CHROMA_PATH)
    print(f"‚úÖ Connected to ChromaDB at {CHROMA_PATH} successfully!")
except Exception as e:
    print(f"‚ùå Error connecting to ChromaDB: {e}")
    exit()

products_chroma_collection = chroma_client.get_or_create_collection(
    name="product_vectors",
    embedding_function=sbert_ef
)
newstrend_chroma_collection = chroma_client.get_or_create_collection(
    name="newstrend_vectors",
    embedding_function=sbert_ef
)

# ==========================
# 4. X·ª¨ L√ù D·ªÆ LI·ªÜU S·∫¢N PH·∫®M
# ==========================
def process_products_data():
    print("\nüõçÔ∏è Processing products data...")
    documents_to_add, ids_to_add, metadatas_to_add = [], [], []

    all_products = products_collection.find({"isDeleted": {"$ne": True}})
    for product in all_products:
        name = product.get("name", "")
        description = product.get("description", "")
        price = product.get("price", 0)
        discount = product.get("discount", 0)
        publish_year = product.get("publishYear", "")
        dimensions = product.get("dimensions", "")
        weight = product.get("weight", "")
        page = product.get("page", "")

        # --- JOIN c√°c b·∫£ng li√™n quan ---
        def get_name_by_id(collection, oid):
            if isinstance(oid, ObjectId):
                doc = collection.find_one({"_id": oid})
                if doc:
                    return doc.get("name", "")
            return ""

        author_name = get_name_by_id(authors_collection, product.get("author"))
        publisher_name = get_name_by_id(publishers_collection, product.get("publisher"))
        language_name = get_name_by_id(languages_collection, product.get("language"))
        format_name = get_name_by_id(formats_collection, product.get("format"))
        category_name = get_name_by_id(categories_collection, product.get("category"))

        # --- GH√âP TH√ÄNH TEXT GI√ÄU NG·ªÆ NGHƒ®A ---
        combined_text = (
            f"T√™n s·∫£n ph·∫©m: {name}. "
            f"T√°c gi·∫£: {author_name}. "
            f"Th·ªÉ lo·∫°i: {category_name}. "
            f"Nh√† xu·∫•t b·∫£n: {publisher_name}. "
            f"Ng√¥n ng·ªØ: {language_name}. "
            f"ƒê·ªãnh d·∫°ng: {format_name}. "
            f"NƒÉm xu·∫•t b·∫£n: {publish_year}. "
            f"Tr·ªçng l∆∞·ª£ng: {weight} gram. "
            f"K√≠ch th∆∞·ªõc: {dimensions}. "
            f"S·ªë trang: {page}. "
            f"Gi√°: {price} ƒë·ªìng. Gi·∫£m gi√°: {discount}%. "
            f"M√¥ t·∫£: {description}"
        )

        documents_to_add.append(combined_text)
        ids_to_add.append(str(product["_id"]))
        metadatas_to_add.append({
            "mongo_id": str(product["_id"]),
            "name": name,
            "author": author_name,
            "category": category_name,
            "publisher": publisher_name,
            "language": language_name,
            "format": format_name,
            "price": price
        })

    if documents_to_add:
        print(f"Generating embeddings for {len(documents_to_add)} products...")
        embeddings = get_embeddings(documents_to_add)
        products_chroma_collection.add(
            embeddings=embeddings,
            documents=documents_to_add,
            metadatas=metadatas_to_add,
            ids=ids_to_add
        )
        print(f"‚úÖ Added {len(documents_to_add)} product vectors to 'product_vectors'.")
    else:
        print("‚ö†Ô∏è No product documents found.")

# ==========================
# 5. X·ª¨ L√ù D·ªÆ LI·ªÜU NEWSTREND
# ==========================
def process_newstrend_data():
    print("\nüì∞ Processing newstrend data...")
    documents_to_add, ids_to_add, metadatas_to_add = [], [], []

    all_news = newstrend_collection.find({})
    for news_item in all_news:
        title = news_item.get("title", "")
        snippet = news_item.get("contentSnippet", "")
        link = news_item.get("link", "")
        iso_date = news_item.get("isoDate", "")

        combined_text = (
            f"Ti√™u ƒë·ªÅ tin t·ª©c: {title}. "
            f"T√≥m t·∫Øt: {snippet}. "
            f"Ng√†y ƒëƒÉng: {iso_date}. "
            f"ƒê∆∞·ªùng d·∫´n: {link}"
        )

        documents_to_add.append(combined_text)
        ids_to_add.append(str(news_item["_id"]))
        metadatas_to_add.append({
            "mongo_id": str(news_item["_id"]),
            "title": title,
            "link": link,
            "date": iso_date
        })

    if documents_to_add:
        print(f"Generating embeddings for {len(documents_to_add)} news items...")
        embeddings = get_embeddings(documents_to_add)
        newstrend_chroma_collection.add(
            embeddings=embeddings,
            documents=documents_to_add,
            metadatas=metadatas_to_add,
            ids=ids_to_add
        )
        print(f"‚úÖ Added {len(documents_to_add)} newstrend vectors to 'newstrend_vectors'.")
    else:
        print("‚ö†Ô∏è No newstrend documents found.")

# ==========================
# 6. MAIN
# ==========================
if __name__ == "__main__":
    process_products_data()
    process_newstrend_data()
    print("\nüéØ Vectorization process completed successfully!")
    mongo_client.close()
    print("üîí MongoDB connection closed.")
