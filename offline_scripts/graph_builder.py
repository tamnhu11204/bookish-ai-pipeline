import os
import sys
import networkx as nx
import pickle
from itertools import combinations
from dotenv import load_dotenv

# ==========================
# 0. THI·∫æT L·∫¨P PATH ƒê·ªÇ IMPORT
# ==========================
# Th√™m th∆∞ m·ª•c g·ªëc (ai_service) v√†o Python Path ƒë·ªÉ c√≥ th·ªÉ import t·ª´ `app`
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

# ==========================
# 1. IMPORT C√ÅC TH√ÄNH PH·∫¶N ƒê√É MODULE H√ìA
# ==========================
from app.connect_db.mongo_client import products_collection
from app.connect_db.vector_db import products_chroma_collection

# T·∫£i c√°c bi·∫øn m√¥i tr∆∞·ªùng t·ª´ file .env
load_dotenv()

# ==========================
# 2. C·∫§U H√åNH SCRIPT
# ==========================
# L·∫•y ƒë∆∞·ªùng d·∫´n file output t·ª´ .env, c√≥ gi√° tr·ªã m·∫∑c ƒë·ªãnh
GRAPH_OUTPUT_FILE = os.getenv("GRAPH_OUTPUT_FILE", "./data/book_graph.gpickle")
SIMILARITY_TOP_K = 5  # S·ªë l∆∞·ª£ng s√°ch t∆∞∆°ng ƒë·ªìng ng·ªØ nghƒ©a c·∫ßn t√¨m cho m·ªói s√°ch


# ==========================
# 3. LOGIC X√ÇY D·ª∞NG GRAPH
# ==========================
def build_book_graph():
    """
    X√¢y d·ª±ng m·ªôt graph quan h·ªá s√°ch bao g·ªìm c·∫£ c√°c m·ªëi quan h·ªá r√µ r√†ng (metadata)
    v√† c√°c m·ªëi quan h·ªá t∆∞∆°ng ƒë·ªìng ng·ªØ nghƒ©a (vector similarity).
    """
    print("\nB·∫Øt ƒë·∫ßu x√¢y d·ª±ng graph quan h·ªá s√°ch...")
    G = nx.Graph()

    # --- B∆∞·ªõc 1: L·∫•y to√†n b·ªô d·ªØ li·ªáu s√°ch t·ª´ MongoDB (s·ª≠ d·ª•ng collection ƒë√£ import) ---
    print("ƒêang l·∫•y d·ªØ li·ªáu s√°ch t·ª´ MongoDB...")
    all_books = list(products_collection.find({"isDeleted": {"$ne": True}}))
    if not all_books:
        print("Kh√¥ng t√¨m th·∫•y s√°ch n√†o trong MongoDB. K·∫øt th√∫c.")
        return

    author_map = {}
    category_map = {}

    print("ƒêang x·ª≠ l√Ω d·ªØ li·ªáu v√† th√™m c√°c node s√°ch v√†o graph...")
    for book in all_books:
        book_id = str(book["_id"])
        G.add_node(
            book_id,
            name=book.get("name", "N/A"),
            author=str(book.get("author")),
            category=str(book.get("category")),
        )
        author_id = str(book.get("author"))
        if author_id:
            author_map.setdefault(author_id, []).append(book_id)

        category_id = str(book.get("category"))
        if category_id:
            category_map.setdefault(category_id, []).append(book_id)

    print(f"ƒê√£ th√™m {G.number_of_nodes()} node s√°ch.")

    # --- B∆∞·ªõc 2: Th√™m c√°c c·∫°nh d·ª±a tr√™n quan h·ªá r√µ r√†ng (c√πng t√°c gi·∫£, th·ªÉ lo·∫°i) ---
    print("ƒêang th√™m c√°c c·∫°nh quan h·ªá r√µ r√†ng (c√πng t√°c gi·∫£, c√πng th·ªÉ lo·∫°i)...")
    for author_id, book_ids in author_map.items():
        for book1, book2 in combinations(book_ids, 2):
            G.add_edge(book1, book2, relationship="same_author")

    for category_id, book_ids in category_map.items():
        for book1, book2 in combinations(book_ids, 2):
            if not G.has_edge(book1, book2):
                G.add_edge(book1, book2, relationship="same_category")

    print(f"S·ªë c·∫°nh hi·ªán t·∫°i sau khi th√™m quan h·ªá r√µ r√†ng: {G.number_of_edges()}")

    # --- B∆∞·ªõc 3: Th√™m c√°c c·∫°nh d·ª±a tr√™n t∆∞∆°ng ƒë·ªìng ng·ªØ nghƒ©a t·ª´ ChromaDB ---
    print(
        f"ƒêang th√™m c√°c c·∫°nh t∆∞∆°ng ƒë·ªìng ng·ªØ nghƒ©a t·ª´ ChromaDB (top {SIMILARITY_TOP_K})..."
    )

    # L·∫•y ID c·ªßa t·∫•t c·∫£ c√°c chunk t·ª´ ChromaDB
    chroma_results = products_chroma_collection.get(include=["metadatas"])

    # Gom c√°c chunk l·∫°i theo source_id (product_id)
    product_chunks = {}
    for i, chunk_id in enumerate(chroma_results["ids"]):
        source_id = chroma_results["metadatas"][i].get("source_id")
        if source_id:
            product_chunks.setdefault(source_id, []).append(chunk_id)

    # Truy v·∫•n s√°ch t∆∞∆°ng ƒë·ªìng cho m·ªói cu·ªën s√°ch
    product_ids_in_graph = list(G.nodes)
    for i, book_id in enumerate(product_ids_in_graph):
        if book_id not in product_chunks:
            continue

        try:
            # Query b·∫±ng embedding c·ªßa chunk ƒë·∫ßu ti√™n c·ªßa s√°ch ƒë√≥
            query_embedding = products_chroma_collection.get(
                ids=product_chunks[book_id][0], include=["embeddings"]
            )["embeddings"][0]

            results = products_chroma_collection.query(
                query_embeddings=[query_embedding],
                n_results=SIMILARITY_TOP_K + 5,  # L·∫•y nhi·ªÅu h∆°n ƒë·ªÉ l·ªçc
            )

            # X·ª≠ l√Ω k·∫øt qu·∫£ tr·∫£ v·ªÅ
            similar_product_ids = set()
            for j, distance in enumerate(results["distances"][0]):
                meta = results["metadatas"][0][j]
                similar_id = meta.get("source_id")

                if similar_id and similar_id != book_id and similar_id in G:
                    similar_product_ids.add((similar_id, distance))

            # Th√™m c·∫°nh cho K s√°ch g·∫ßn nh·∫•t
            sorted_similar = sorted(list(similar_product_ids), key=lambda x: x[1])
            for similar_id, distance in sorted_similar[:SIMILARITY_TOP_K]:
                similarity_score = 1 - distance
                if similarity_score > 0 and not G.has_edge(book_id, similar_id):
                    G.add_edge(
                        book_id,
                        similar_id,
                        relationship="semantically_similar",
                        weight=round(similarity_score, 4),
                    )
        except Exception as e:
            print(f"[L·ªñI] Kh√¥ng th·ªÉ truy v·∫•n s√°ch t∆∞∆°ng ƒë·ªìng cho {book_id}: {e}")

        if (i + 1) % 100 == 0:
            print(f"  ƒê√£ x·ª≠ l√Ω {i + 1}/{len(product_ids_in_graph)} s√°ch...")

    print(
        f"X√¢y d·ª±ng graph ho√†n t·∫•t. T·ªïng s·ªë node: {G.number_of_nodes()}, T·ªïng s·ªë c·∫°nh: {G.number_of_edges()}"
    )

    # --- B∆∞·ªõc 4: L∆∞u graph v√†o file ---
    print(f"ƒêang l∆∞u graph v√†o file: '{GRAPH_OUTPUT_FILE}'...")
    # T·ª± ƒë·ªông t·∫°o th∆∞ m·ª•c ch·ª©a file n·∫øu ch∆∞a t·ªìn t·∫°i
    output_dir = os.path.dirname(GRAPH_OUTPUT_FILE)
    if output_dir:
        os.makedirs(output_dir, exist_ok=True)

    with open(GRAPH_OUTPUT_FILE, "wb") as f:
        pickle.dump(G, f)
    print("‚úÖ ƒê√£ l∆∞u graph th√†nh c√¥ng.")

    return G


# ==========================
# 4. ƒêI·ªÇM B·∫ÆT ƒê·∫¶U CH·∫†Y SCRIPT
# ==========================
if __name__ == "__main__":
    build_book_graph()
    print("\nüéâ X√¢y d·ª±ng graph ho√†n t·∫•t!")
